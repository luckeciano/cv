\vspace18pt \small I am a professional with a mixed background in research and engineering. In recent years, my main work applied Deep Learning and Reinforcement Learning algorithms for real-world scenarios at scale. My research curiosity is to **develop agents that learn behaviors through interaction, in an efficient, generalist, and adaptive way. I believe these agents emerge from \textbfrepresentation learning, \textbfworld models, and \textbfintrinsically-motivated decision-making. This motivates me to work in the intersection of (Model-Based) Reinforcement Learning, Probabilistic Modeling, and Foundation Models. **


## <i class="fa fa-chevron-right"></i> Education

<table class="table table-hover">
  <tr>
    <td>
      <strong>PhD in Computer Science</strong>, University of Oxford
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Reinforcement Learning, Probabilistic Modeling, and Large Language Models
        <br> Member of the <a href="https://oatml.cs.ox.ac.uk/" target="_blank">Oxford Applied and Theoretical Machine Learning Group</a>
        <br> Supervised by Yarin Gal and Alessandro Abate
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2023 - Present</td>
  </tr>
  <tr>
    <td>
      <strong>MSc. in EECS</strong>, Aeronautics Institute of Technology (ITA)
        (3.73/4.00)
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Thesis: Imitation Learning and Meta-Learning for Optimizing Humanoid Robot Motions
        <br> Best Master's Dissertation in Brazilian AI Awards 2019 (DATA-H)
        <br> Winner of the V Best MSc Dissertation and PhD Thesis Contest in Robotics (Brazilian Robotics Society)
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2017 - 2019</td>
  </tr>
  <tr>
    <td>
      <strong>BSc. in Computer Engineering</strong>, Aeronautics Institute of Technology (ITA)
        (3.51/4.00)
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Acceptance Rate: 2.3%
        <br> Thesis: A Deep Reinforcement Learning Method for Humanoid Kick
        <br> Computer Engineering Best Thesis Award
        <br> Honors in Software Engineering in undergraduate and graduate departments
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2014 - 2018</td>
  </tr>
</table>


## <i class="fa fa-chevron-right"></i> Industry Experience
<table class="table table-hover">
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Microsoft</strong>,
Seattle, WA
Tech Leader for the Semantic Document project in the Bing Document Understanding Team
Worked with Multi-Modal Representation Learning for Web Data Semantic Understanding
Led the development of the first HTML-based deep learning model for Semantic Document extraction that scaled to 400 billion documents
Developed a LLM-based pipeline for Semantic Document label extraction, reducing the cost of labeling data considerably and improving model quality by 20%
Responsibilities: Data Engineering, Data Analysis and Feature Engineering, Model Development, Deployment and Monitoring
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2021 - 2023</td>
</tr>
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Microsoft</strong>,
Vancouver, BC
Worked building up a microservices-based infrastructure to enable data transfer and processing from SQL databases to Azure Data Lake at scale
Comprises delivering high quality, scalable code for asynchronous, distributed, and multi-threaded applications in the context of SaaS in the cloud
Other responsibilities: architectural discussions, code reviews, cluster and CI/CD pipelines management, livesite
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2020 - 2021</td>
</tr>
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Deep Learning Brazil Research Lab</strong>,
Remote, Part-Time
DeepFood Project: Worked implementing Deep Learning and RL models for Recommender Systems for a major player in food delivery. Released an <a href="https://arxiv.org/abs/2010.07035" target="_blank">open-source framework</a> to model, train, and evaluate RL agents for marketplaces, with automated off-policy and fairness evaluation. Developed a <a href="https://dl.acm.org/doi/10.1145/3383313.3412209" target="_blank">contextual meta-bandit</a> approach for model selection.
PulseRL project: Led a team of 3 student researchers to develop an offline RL agent (<a href="https://api.semanticscholar.org/CorpusID:249703190" target="_blank">PulseRL</a>) based on the Conservative Q-Learning framework for Debt Collection. Deployed PulseRL in a production system to handle millions of users daily.
Recovery project: Led a team of 10 student researchers to develop contextual bandit agents trained in historical data for Debt negotiation, improving the performance in 50% of the user traffic. Under patent.
Responsibilities: RL Core Research, RL applications with industry partners, Manage/Supervise teams of graduate students
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2019 - 2023</td>
</tr>
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Amazon Web Services</strong>,
Cape Town, South Africa
Worked at the EC2 Core Platform, in the Host Placement Team
Developed a Continuous Deployment Pipeline for the instances metering service, based on several testing mechanisms to evaluate metering data
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2018</td>
</tr>
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>VTEX</strong>,
Rio de Janeiro, Brazil
Developed several features for the platform infrastructure (logs and monitoring, caching, throttling systems), developed microservices and managed Kubernetes clusters.
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2018</td>
</tr>
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Pearson Education</strong>,
Sao Paulo, Brazil
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2016</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Relevant Technical Skills
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Core Skills</td>
  <td>
Artificial Intelligence (Deep Learning / Reinforcement Learning), Probablistic Modeling, Software Engineering, Optimization, Robotics
  </td>
</tr>
<tr>
  <td class='col-md-2'>Research Areas</td>
  <td>
Reinforcement Learning (Offline RL, Meta-RL, Inverse RL), Representation Learning
  </td>
</tr>
<tr>
  <td class='col-md-2'>Programming</td>
  <td>
Python, C/C++; C\# (.NET), Bash, SQL, Java, MATLAB
  </td>
</tr>
<tr>
  <td class='col-md-2'>Frameworks</td>
  <td>
Pytorch, TF/Keras, numpy/matplotlib/pandas/sklearn/huggingface, Azure/AWS/GCP, Kubernetes
  </td>
</tr>
<tr>
  <td class='col-md-2'>OS</td>
  <td>
Linux, Windows, MacOS
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Honors & Awards
<table class="table table-hover">
<tr>
  <td>
    <a href="https://software.intel.com/en-us/ai-academy/ambassadors" target="_blank">Intel AI Student Ambassador</a>
  </td>
  <td class='col-md-2' style='text-align:right;'>2018 - 2020</td>
</tr>
<tr>
  <td>
    Selected to attend to <a href="https://khipu.ai/" target="_blank">Khipu</a>: Latin American Meeting for AI
  </td>
  <td class='col-md-2' style='text-align:right;'>2019</td>
</tr>
<tr>
  <td>
    1st place at Data Science Challenge at EEF (Kaggle's Competition)
  </td>
  <td class='col-md-2' style='text-align:right;'>2019</td>
</tr>
<tr>
  <td>
    4th place at the RoboCup 3D Soccer Simulation Scientific Challenge (Sydney, Australia)
  </td>
  <td class='col-md-2' style='text-align:right;'>2019</td>
</tr>
<tr>
  <td>
    2nd place in the Soccer 3D Simulation League in the Latin America Robot Competition
  </td>
  <td class='col-md-2' style='text-align:right;'>2015, 2016, 2017, 2018</td>
</tr>
<tr>
  <td>
    6th, 9th, and 7th in the RoboCup 3D Soccer Simulation League
  </td>
  <td class='col-md-2' style='text-align:right;'>2016, 2017, 2019</td>
</tr>
<tr>
  <td>
    1st place Microsoft Code Competition at ITA
  </td>
  <td class='col-md-2' style='text-align:right;'>2017</td>
</tr>
<tr>
  <td>
    2nd Place Quero Education Hackathon for <a href="https://github.com/mknarciso/lassie" target="_blank">Lassie, the Learning Assistant</a>
  </td>
  <td class='col-md-2' style='text-align:right;'>2017</td>
</tr>
<tr>
  <td>
    3rd Place at Quero Education Hackathon for <a href="https://github.com/AcademiaBarbaNegra" target="_blank">Ahoy!</a>
  </td>
  <td class='col-md-2' style='text-align:right;'>2016</td>
</tr>
<tr>
  <td>
    Scientific Competitions in High School
    <br><p style="color:grey;font-size:1.2rem">Physics (5 medals), Chemistry (8 medals), Astronomy (2 medals)
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2011 - 2013</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Publications

<!-- [<a href="https://github.com/bamos/cv/blob/master/publications/all.bib">BibTeX</a>] -->
Representative publications that I am a primary author on are
<span style='background-color: #ffffd0'>highlighted.</span>
<br>
[<a href="https://scholar.google.com/citations?user=b2aBi8UAAAAJ">Google Scholar</a>]

<h2>2025</h2>
<table class="table table-hover">

<tr id="tr-capo" style="background-color: #ffffd0">
<td>
    <em>Stabilizing Policy Gradients for Sample-Efficient Reinforcement Learning in LLM Reasoning</em><br>
    Luckeciano&nbsp;Melo, Alessandro&nbsp;Abate, and Yarin&nbsp;Gal<br>
    (In Submission) 2025  <br>
    [1] <br>
    
</td>
</tr>


<tr id="tr-tdvcl" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/2410.07812' target='_blank'>Temporal-Difference Variational Continual Learning</a> </em><br>
    Luckeciano&nbsp;Melo, Alessandro&nbsp;Abate, and Yarin&nbsp;Gal<br>
    Advances in Neural Information Processing Systems (**NeurIPS**) 2025  <br>
    [2] <br>
    
</td>
</tr>


<tr id="tr-slidingpuzzles" >
<td>
    <em><a href='https://arxiv.org/abs/2410.14038' target='_blank'>Sliding Puzzles Gym: A Scalable Benchmark for State Representation in Visual Reinforcement Learning</a> </em><br>
    Bryan&nbsp;Oliveira, Murilo&nbsp;Luz, Bruno&nbsp;Brand\~ao, Luana&nbsp;Martins, Telma&nbsp;Soares, and Luckeciano&nbsp;Melo<br>
    International Conference on Machine Learning (**ICML**) 2025  <br>
    [3] <br>
    
</td>
</tr>


<tr id="tr-infoquest" >
<td>
    <em><a href='https://arxiv.org/abs/2502.12257' target='_blank'>InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context</a> </em><br>
    Bryan&nbsp;Oliveira, Luana&nbsp;Martins, Bruno&nbsp;Brand\~ao, and Luckeciano&nbsp;Melo<br>
    Workshop on Scaling Self-Improving Foundation Models at International Conference on Learning Representations (**ICLR**) 2025  <br>
    [4] <br>
    
</td>
</tr>


<tr id="tr-uqgrm" >
<td>
    <em><a href='https://arxiv.org/abs/2502.11250' target='_blank'>Uncertainty-Aware Step-wise Verification with Generative Reward Models</a> </em><br>
    Zihuiwen&nbsp;Ye, Luckeciano&nbsp;Melo, Younesse&nbsp;Kaddar, Phil&nbsp;Blunsom, Sam&nbsp;Staton, and Yarin&nbsp;Gal<br>
    Workshop on Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI at International Conference on Learning Representations (**ICLR**) 2025  <br>
    [5] <br>
    
</td>
</tr>

</table>
<h2>2024</h2>
<table class="table table-hover">

<tr id="tr-balpm" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/2406.10023' target='_blank'>Deep Bayesian Active Learning for Preference Modeling in Large Language Models</a> </em><br>
    Luckeciano&nbsp;Melo, Panagiotis&nbsp;Tigas, Alessandro&nbsp;Abate, and Yarin&nbsp;Gal<br>
    Advances in Neural Information Processing Systems (**NeurIPS**) 2024  <br>
    [6] <br>
    
</td>
</tr>

</table>
<h2>2022</h2>
<table class="table table-hover">

<tr id="tr-trmrl" style="background-color: #ffffd0">
<td>
    <em><a href='https://proceedings.mlr.press/v162/melo22a.html' target='_blank'>Transformers are Meta-Reinforcement Learners</a> </em><br>
    Luckeciano&nbsp;Melo<br>
    International Conference on Machine Learning (**ICML**) 2022  <br>
    [7] <br>
    
</td>
</tr>


<tr id="tr-ieeeaccess" >
<td>
    <em><a href='https://ieeexplore.ieee.org/abstract/document/9817118' target='_blank'>Multi-Agent Reinforcement Learning for Strategic Decision Making and Control in Robotic Soccer through Self-Play</a> </em><br>
    Bruno&nbsp;Brand\~ao, Telma&nbsp;De&nbsp;Lima, Anderson&nbsp;Soares, Luckeciano&nbsp;Melo, and Marcos&nbsp;Maximo<br>
    IEEE Access 2022  <br>
    [8] <br>
    
</td>
</tr>

</table>
<h2>2021</h2>
<table class="table table-hover">

<tr id="tr-pulserl" style="background-color: #ffffd0">
<td>
    <em><a href='https://offline-rl-neurips.github.io/2021/pdf/9.pdf' target='_blank'>PulseRL: Enabling Offline Reinforcement Learning for Digital Marketing Systems via Conservative Q-Learning</a> </em><br>
    Luckeciano&nbsp;Melo*, Luana&nbsp;Martins*, Bryan&nbsp;Oliveira*, Bruno&nbsp;Brand\~ao, Douglas&nbsp;W&nbsp;Soares, and Telma&nbsp;Lima<br>
    2nd Offline Reinforcement Learning Workshop at Neural Information Processing Systems (**NeurIPS**) 2021 (*co-lead authors, **Oral Presentation**) <br>
    [9] <br>
    
</td>
</tr>


<tr id="tr-jint" style="background-color: #ffffd0">
<td>
    <em><a href='https://link.springer.com/article/10.1007/s10846-021-01355-9' target='_blank'>Learning Humanoid Robot Running Motions with Symmetry Incentive through Proximal Policy Optimization</a> </em><br>
    Luckeciano&nbsp;Melo*, Dicksiano&nbsp;Melo*, and Marcos&nbsp;Maximo<br>
    Journal of Intelligent and Robotic Systems 2021 (*co-lead authors) <br>
    [10] <br>
    
</td>
</tr>

</table>
<h2>2020</h2>
<table class="table table-hover">

<tr id="tr-mars-gym" style="background-color: #ffffd0">
<td>
    <em><a href='https://offline-rl-neurips.github.io/pdf/21.pdf' target='_blank'>MARS-Gym: Offline Reinforcement Learning for Recommender Systems in Marketplaces</a> </em><br>
    Luckeciano&nbsp;Melo*, Marlesson&nbsp;RO&nbsp;Santana*, Fernando&nbsp;HF&nbsp;Camargo*, Bruno&nbsp;Brand\~ao*, Anderson&nbsp;Soares, Renan&nbsp;M&nbsp;Oliveira, and Sandor&nbsp;Caetano<br>
    Challenges of Real-World Reinforcement Learning at the 34th Conference on Neural Information Processing Systems (**NeurIPS**) 2020 (*co-lead authors, **Oral Presentation**) <br>
    [11] <br>
    
</td>
</tr>


<tr id="tr-santana2020contextual" style="background-color: #ffffd0">
<td>
    <em><a href='https://dl.acm.org/doi/10.1145/3383313.3412209' target='_blank'>Contextual Meta-Bandit for Recommender Systems Selection</a> </em><br>
    Luckeciano&nbsp;Melo*, Marlesson&nbsp;RO&nbsp;Santana*, Fernando&nbsp;HF&nbsp;Camargo*, Bruno&nbsp;Brand\~ao*, Anderson&nbsp;Soares, Renan&nbsp;M&nbsp;Oliveira, and Sandor&nbsp;Caetano<br>
    ACM Conference on Recommender Systems 2020 (*co-lead authors) <br>
    [12] <br>
    
</td>
</tr>

</table>
<h2>2019</h2>
<table class="table table-hover">

<tr id="tr-melo2019a" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/1910.10232' target='_blank'>Bottom-Up Meta-Policy Search</a> </em><br>
    Luckeciano&nbsp;Melo and Marcos&nbsp;Maximo<br>
    Deep Reinforcement Learning Workshop in the 33rd Conference on Neural Information Processing Systems (**NeurIPS**) 2019  <br>
    [13] <br>
    
</td>
</tr>


<tr id="tr-melo2019a" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/1910.10620' target='_blank'>Learning Humanoid Robot Running Skills through Proximal Policy Optimization</a> </em><br>
    Luckeciano&nbsp;Melo and Marcos&nbsp;Maximo<br>
    Latin America Robotics Symposium (LARS) 2019 (**LARS 2019 Best Paper Award**) <br>
    [14] <br>
    
</td>
</tr>


<tr id="tr-Afonso2019HousingPP" style="background-color: #ffffd0">
<td>
    <em><a href='https://api.semanticscholar.org/CorpusID:214699727' target='_blank'>Housing Prices Prediction with a Deep Learning and Random Forest Ensemble</a> </em><br>
    Bruno&nbsp;Klaus&nbsp;de&nbsp;Aquino&nbsp;Afonso, Luckeciano&nbsp;Melo, Willian&nbsp;Oliveira, Samuel&nbsp;Bruno&nbsp;da&nbsp;Silva&nbsp;Sousa, and Lilian&nbsp;Berton<br>
    ENIAC 2019  <br>
    [15] <br>
    
</td>
</tr>


<tr id="tr-stanfordbook" style="background-color: #ffffd0">
<td>
    <em><a href='https://tinyurl.com/3b92dzjz' target='_blank'>A experiencia do grupo academico ITAndroids (The experience from ITAndroids academic group)</a> </em><br>
    Luckeciano&nbsp;Melo, Julio&nbsp;Cesar&nbsp;Filho, Felipe&nbsp;Pinheiro, and Maximo&nbsp;Marcos<br>
    Robotica Educacional: experiencias inovadoras na educacao brasileira (Educational Robotics: innovative experiences in brazilian education). Book Chapter (Penso Publisher) 2019  <br>
    [16] <br>
    
</td>
</tr>

</table>
<h2>2018</h2>
<table class="table table-hover">

<tr id="tr-melo2018" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/1901.00270' target='_blank'>Learning Humanoid Motions through Deep Neural Networks</a> </em><br>
    Luckeciano&nbsp;Melo, Marcos&nbsp;Maximo, and Adilson&nbsp;Marques&nbsp;Cunha<br>
    Brazilian Humanoid Robot Workshop (BRAHUR) 2018  <br>
    [17] <br>
    
</td>
</tr>

</table>


## <i class="fa fa-chevron-right"></i> Repositories
<table class="table table-hover">
<tr>
  <td>
    <a href="https://github.com/luckeciano/BAL-PM">luckeciano/BAL-PM</a> |
    <i class="fa fas fa-star"></i> 4 |
    <em>Deep Bayesian Active Learning for Preference Modeling in Large Language Models</em>
    <!--  -->
    <!--     luckeciano/BAL-PM  -->
    <!--  -->
  </td>
  <td class='col-md-2' style='text-align:right;'>2024</td>
</tr>
<tr>
  <td>
    <a href="https://github.com/luckeciano/transformers-metarl">luckeciano/transformers-metarl</a> |
    <i class="fa fas fa-star"></i> 42 |
    <em>Transformers are Meta-Reinforcement Learners (ICML 2022)</em>
    <!--  -->
    <!--     luckeciano/transformers-metarl  -->
    <!--  -->
  </td>
  <td class='col-md-2' style='text-align:right;'>2022</td>
</tr>
<tr>
  <td>
    <a href="https://github.com/dlb-rl/pulse-rl">dlb-rl/pulse-rl</a> |
    <i class="fa fas fa-star"></i> 8 |
    <em>PulseRL - Enabling Offline Reinforcement Learning for Digital Marketing Systems via Conservative Q-Learning.</em>
    <!--  -->
    <!--     dlb-rl/pulse-rl  -->
    <!--  -->
  </td>
  <td class='col-md-2' style='text-align:right;'>2021</td>
</tr>
<tr>
  <td>
    <a href="https://github.com/deeplearningbrasil/mars-gym">deeplearningbrasil/mars-gym</a> |
    <i class="fa fas fa-star"></i> 49 |
    <em>MARS-Gym - a benchmark framework for modeling, training, and evaluating RL-based recommender systems for marketplaces.</em>
    <!--  -->
    <!--     deeplearningbrasil/mars-gym  -->
    <!--  -->
  </td>
  <td class='col-md-2' style='text-align:right;'>2020</td>
</tr>
<tr>
  <td>
    <a href="https://github.com/marlesson/meta-bandit-selector">marlesson/meta-bandit-selector</a> |
    <i class="fa fas fa-star"></i> 9 |
    <em>Contextual Meta-Bandit for Recommender Systems Selection</em>
    <!--  -->
    <!--     marlesson/meta-bandit-selector  -->
    <!--  -->
  </td>
  <td class='col-md-2' style='text-align:right;'>2020</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Invited Talks
<table class="table table-hover">
<tr>
  <td>
        WhiRL Reading Group at Oxford
  </td>
  <td class='col-md-2' style='text-align:right;'>June 2022</td>
</tr>
<tr>
  <td>
        Microsoft Research
  </td>
  <td class='col-md-2' style='text-align:right;'>June 2022</td>
</tr>
<tr>
  <td>
        Microsoft
  </td>
  <td class='col-md-2' style='text-align:right;'>February 2022</td>
</tr>
<tr>
  <td>
        <a href="https://youtu.be/Ycggd_Bg6nY">Deep Learning Brazil Summer School</a>
  </td>
  <td class='col-md-2' style='text-align:right;'>Feb 2018</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Advising
<table class="table table-hover">
<tr>
  <td>
        <a href="https://bryanoliveira.github.io/">Bryan Oliveira</a> (MSc Student `24) - Representation Learning for Visual RL
  </td>
  <td class='col-md-2' style='text-align:right;'>2024</td>
</tr>
<tr>
  <td>
        <a href="https://harryzxi.github.io/">Harry Xi</a> (MSc Student `25) - Bayesian Variational Preference Modeling
  </td>
  <td class='col-md-2' style='text-align:right;'>2025</td>
</tr>
<tr>
  <td>
        <a href="https://www.linkedin.com/in/samuel-dower-128702234/">Samuel Dower</a> (MSc Student `25) - Uncertainty-Aware Reward Modeling with STARC Metrics
  </td>
  <td class='col-md-2' style='text-align:right;'>2025</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Peer Review
<table class="table table-hover">
<tr>
  <td>
      Conference on Machine Learning (ICML)
  <td class='col-md-2' style='text-align:right;'>2022, 2023, 2024, 2025</td>
  </td>
</tr>
<tr>
  <td>
      Conference on Neural Information Processing Systems (NeurIPS)
  <td class='col-md-2' style='text-align:right;'>2022, 2023, 2024, 2025</td>
  </td>
</tr>
<tr>
  <td>
      Conference on Learning Representations (ICLR)
  <br><p style="color:grey;font-size:1.2rem">(*Outstanding Reviewer)</p>
  <td class='col-md-2' style='text-align:right;'>2022*, 2023, 2024, 2025</td>
  </td>
</tr>
<tr>
  <td>
      Conference on Autonomous Agents and Multiagent Systems (AAMAS)
  <td class='col-md-2' style='text-align:right;'>2024</td>
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Professional Activities
<table class="table table-hover">
<tr>
  <td>
     <a href="https://offline-rl-neurips.github.io/2021">Program Committee - NeurIPS Offline Reinforcement Learning Workshop</a>
  <td class='col-md-2' style='text-align:right;'>2021, 2022</td>
  </td>
</tr>
<tr>
  <td>
     <a href="https://sites.google.com/view/fmdm-neurips23/">Program Committee - NeurIPS Foundation Models for Decision Making Workshop</a>
  <td class='col-md-2' style='text-align:right;'>2022, 2023</td>
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Other Academic and Research Experiences

<table class="table table-hover">
  <tr>
    <td>
      <strong></strong>, 
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Worked on Soccer 3D strategy. Worked on build up the C++ base code team in the first year. Developed algorithms to Path Planning, Robot`s Active Vision and Positioning/Marking System.
        <br> Taught fresh students in Software Engineering
        <br> Developed humanoid robot skills for RoboCup 3D Soccer Simulation environment, using Deep Reinforcement Learning, Imitation Learning, Meta-Learning and Evolution Strategies
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2015 - 2019</td>
  </tr>
  <tr>
    <td>
      <strong></strong>, 
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Mentored a student in a research project to develop policies for multi-agent positioning using imitation learning from human feedback.
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2018</td>
  </tr>
  <tr>
    <td>
      <strong></strong>, 
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Taught Deep Learning for graduate students in a course called CT-221: Neural Networks
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2018</td>
  </tr>
  <tr>
    <td>
      <strong></strong>, 
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Worked using Deep Learning for Facial Recognition in Biometric systems, replacing an Eigenfaces` solution with CNNs, improving Identification Rate from 40% to 90%
        <br> Worked in feature engineering for credit card anti-fraud systems
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2017</td>
  </tr>
  <tr>
    <td>
      <strong></strong>, 
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Worked on Software Engineering research for agile methodologies.
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2014 - 2016</td>
  </tr>
</table>
